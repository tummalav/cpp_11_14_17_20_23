# STL vs Abseil vs Folly Containers - Complete Comparison Guide

## Executive Summary

For ultra-low latency trading systems, modern container libraries offer **40-80% performance improvements** over STL containers with **30-60% memory savings**.

### Quick Recommendation

| Use Case | Container | Improvement | Why |
|----------|-----------|-------------|-----|
| **Order tracking** | `abseil::flat_hash_map` | 50% faster | Cache-friendly, low memory |
| **Order book levels** | `abseil::btree_map` | 50% faster | Range queries, ordered |
| **Reference data** | `folly::sorted_vector_map` | 70% faster | Read-only, minimal memory |
| **Symbol cache** | `abseil::flat_hash_map` | 50% faster | Fast lookups, memory efficient |
| **Position tracking** | `abseil::flat_hash_map` | 50% faster | Updates + lookups |

---

## Table of Contents

1. [Performance Comparison](#performance-comparison)
2. [Hash Maps](#hash-maps)
3. [Ordered Maps](#ordered-maps)
4. [Trading Use Cases](#trading-use-cases)
5. [Installation Guide](#installation-guide)
6. [Decision Matrix](#decision-matrix)

---

## Performance Comparison

### Hash Maps (ns/operation)

| Container | Insert | Lookup | Erase | Memory vs STL |
|-----------|--------|--------|-------|---------------|
| `std::unordered_map` | 60-80 | 50-70 | 50-80 | 100% (baseline) |
| `abseil::flat_hash_map` | 30-40 | 25-35 | 30-40 | **50-70%** â­ |
| `folly::F14FastMap` | 20-30 | 20-30 | 25-35 | **40-60%** â­â­ |

**Key Insight**: Abseil and Folly are **2-3x faster** than STL with **40-60% less memory**!

### Ordered Maps (ns/operation)

| Container | Insert | Lookup | Range Query | Memory vs STL |
|-----------|--------|--------|-------------|---------------|
| `std::map` | 100-150 | 80-120 | 500-1000 | 100% (baseline) |
| `abseil::btree_map` | 60-90 | 40-60 | 200-400 | **50-70%** â­ |
| `folly::sorted_vector_map` | O(n) âŒ | 20-40 | 100-200 | **20-40%** â­â­ |

**Key Insight**: B-trees are **2x faster** than Red-Black trees. Sorted vectors are **3-4x faster** for reads!

---

## Hash Maps

### 1. `std::unordered_map` (STL)

**Architecture:**
- Linked-list buckets (chaining)
- Separate nodes for each element
- Pointer per element (high overhead)

**Characteristics:**
```
Memory Layout:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Bucket  â”‚â”€â”€â”€â†’â”‚ Node â”‚â”€â”€â”€â†’â”‚ Node â”‚â”€â”€â”€â†’ null
â”‚ Array   â”‚    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Poor cache locality: Each lookup follows pointers
```

**Performance:**
- âœ“ Standard, portable
- âœ— Slow lookups (50-70ns)
- âœ— High memory overhead
- âœ— Poor cache locality

**Use When:**
- Portability is critical
- Prototyping (optimize later)

---

### 2. `abseil::flat_hash_map` (Google)

**Architecture:**
- **Swiss Tables** algorithm
- Open addressing (flat/linear probing)
- SSE2/SSSE3 optimized probing
- Control bytes for fast searching

**Characteristics:**
```
Memory Layout:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [ctrl][ctrl][ctrl][ctrl]...[ctrl]  â”‚  â† Control bytes (SIMD)
â”‚ [key1][val1][key2][val2]...[keyN]  â”‚  â† Flat array
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Excellent cache locality: Contiguous memory
```

**Performance:**
- âœ“ 50% faster than `std::unordered_map`
- âœ“ 40% less memory
- âœ“ Cache-friendly
- âœ“ SIMD-optimized
- âœ— Requires Abseil library

**Use When:**
- **Most trading use cases** â­
- Need fast lookups (20-40ns)
- Memory efficiency matters
- Proven in production (Google uses everywhere)

**Code Example:**
```cpp
#include "absl/container/flat_hash_map.h"

absl::flat_hash_map<uint64_t, Order> orders;
orders.reserve(100000);  // Pre-allocate

// Fast insert: ~30ns
orders.insert({order_id, order});

// Fast lookup: ~25ns
auto it = orders.find(order_id);
if (it != orders.end()) {
    // Process order
}
```

---

### 3. `folly::F14FastMap` (Facebook)

**Architecture:**
- **F14 algorithm** (Facebook's design)
- Hybrid of chaining and open addressing
- 14-way associative (14 entries per chunk)
- SIMD probing

**Characteristics:**
```
Memory Layout:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 1: [14 entries + metadata] â”‚
â”‚ Chunk 2: [14 entries + metadata] â”‚
â”‚ Chunk 3: [14 entries + metadata] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Best cache performance of all hash maps!
```

**Performance:**
- âœ“ **60% faster** than `std::unordered_map` â­â­â­
- âœ“ 50% less memory
- âœ“ Best cache locality
- âœ“ Fastest lookups (20-30ns)
- âœ— Requires Folly library (heavy dependencies)

**Use When:**
- Need **absolute best performance**
- Can afford Folly dependencies
- Hot path in trading system

**Code Example:**
```cpp
#include <folly/container/F14Map.h>

folly::F14FastMap<uint64_t, Order> orders;
orders.reserve(100000);

// Fastest insert: ~25ns
orders.insert({order_id, order});

// Fastest lookup: ~20ns
auto it = orders.find(order_id);
```

---

### 4. `folly::F14ValueMap` vs `F14FastMap`

| Feature | F14FastMap | F14ValueMap |
|---------|------------|-------------|
| Storage | Pointer to value | Value inline |
| Best for | Large values (>24 bytes) | Small values (â‰¤24 bytes) |
| Cache hits | Good | **Excellent** â­ |
| Memory | Less overhead | **Minimal** â­ |

**Use `F14ValueMap` for:**
- Small structs (Order, Tick, etc.)
- Maximum cache performance
- Minimal memory usage

---

## Ordered Maps

### 1. `std::map` (STL)

**Architecture:**
- Red-Black Tree (self-balancing BST)
- 3 pointers + color bit per node
- O(log n) operations

**Characteristics:**
```
Tree Structure:
        [40]
       /    \
    [20]    [60]
    /  \    /  \
  [10][30][50][70]

Poor cache locality: Pointers everywhere
```

**Performance:**
- âœ“ Standard, ordered
- âœ— Slow (80-120ns lookups)
- âœ— High memory (24-32 bytes overhead/node)
- âœ— Poor cache locality

---

### 2. `abseil::btree_map` (Google)

**Architecture:**
- **B-Tree** (multi-way tree)
- Node size optimized for cache lines
- Multiple keys per node (better locality)
- O(log n) operations

**Characteristics:**
```
B-Tree Structure (order 4):
        [20, 40, 60]
       /   |   |   \
  [5,10] [25,30] [45,50] [65,70,75]

Excellent cache locality: Multiple keys per node
```

**Performance:**
- âœ“ **50% faster** than `std::map` â­
- âœ“ 40-60% less memory
- âœ“ Excellent for range queries
- âœ“ Cache-friendly
- âœ— Requires Abseil library

**Use When:**
- Need ordered container
- Frequent range queries (order book!)
- Insert/delete operations
- **Best choice for order books** â­

**Code Example:**
```cpp
#include "absl/container/btree_map.h"

// Order book: price -> orders at that level
absl::btree_map<double, OrderList> bids;

// Fast insert: ~60ns
bids.insert({150.25, order_list});

// Fast range query (top 5 levels)
auto it = bids.begin();
for (int i = 0; i < 5 && it != bids.end(); ++i, ++it) {
    process_level(it->first, it->second);
}
```

---

### 3. `folly::sorted_vector_map` (Facebook)

**Architecture:**
- **Sorted `std::vector`**
- Binary search for lookups
- O(n) insert, O(log n) lookup

**Characteristics:**
```
Memory Layout:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [key1][val1][key2][val2]...[keyN][valN] â”‚  â† Contiguous!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Best cache locality possible!
```

**Performance:**
- âœ“ **70% faster lookups** than `std::map` â­â­â­
- âœ“ 70% less memory
- âœ“ Perfect cache locality
- âœ“ Minimal overhead
- âœ— O(n) inserts (use for read-heavy!)

**Use When:**
- **Read-heavy workloads** â­â­â­
- Reference data
- Security master
- Infrequent updates
- Maximum performance for lookups

**Code Example:**
```cpp
#include <folly/sorted_vector_types.h>

// Security reference data (read-only after init)
folly::sorted_vector_map<std::string, SecurityData> securities;

// Build once
std::vector<std::pair<std::string, SecurityData>> data;
// ... populate data ...
securities = folly::sorted_vector_map<...>(
    data.begin(), data.end()
);

// Ultra-fast lookup: ~20ns
auto it = securities.find("AAPL");
```

---

## Trading Use Cases

### Use Case 1: Order Book

**Requirement:**
- Store orders at price levels
- Fast order lookup by ID
- Fast range queries (best bid/ask)
- Frequent inserts/deletes

**Solution:**
```cpp
// Order ID â†’ Order
absl::flat_hash_map<uint64_t, Order*> order_index;

// Price â†’ OrderList (buy side)
absl::btree_map<double, OrderList, std::greater<>> bids;

// Price â†’ OrderList (sell side)
absl::btree_map<double, OrderList> asks;

// Fast operations:
// - Add order:        ~30ns (flat_hash_map) + ~60ns (btree_map) = 90ns
// - Find order:       ~25ns (flat_hash_map)
// - Best bid:         ~5ns  (btree_map.begin())
// - Top 5 levels:     ~50ns (iterate 5 elements)
```

**Performance vs STL:**
- Order lookup: 50% faster
- Price level ops: 50% faster
- Memory: 40% less
- **Total improvement: 2x faster** â­

---

### Use Case 2: Symbol Cache

**Requirement:**
- Store market data for 10,000 symbols
- Ultra-fast lookup (sub-50ns)
- Mostly reads, rare updates
- Memory efficiency

**Solution:**
```cpp
absl::flat_hash_map<std::string, SymbolData> symbol_cache;
symbol_cache.reserve(10000);

// Update (rare)
symbol_cache["AAPL"] = tick_data;  // ~30ns

// Lookup (frequent)
auto it = symbol_cache.find("AAPL");  // ~25ns
if (it != symbol_cache.end()) {
    double mid = (it->second.bid + it->second.ask) / 2.0;
}
```

**Performance:**
- Lookup: 25-35ns (vs 50-70ns STL) = **50% faster**
- Memory: 60% of STL = **40% savings**

---

### Use Case 3: Position Tracking

**Requirement:**
- Track positions for 1,000 accounts
- Fast updates (fills)
- Fast aggregation
- Thread-safe

**Solution 1: Single Map + Lock**
```cpp
absl::flat_hash_map<AccountID, Position> positions;
std::shared_mutex positions_mutex;

// Update (write lock)
{
    std::unique_lock lock(positions_mutex);
    positions[account_id].quantity += fill_qty;  // ~30ns + lock
}

// Read (shared lock)
{
    std::shared_lock lock(positions_mutex);
    auto it = positions.find(account_id);  // ~25ns + lock
}
```

**Solution 2: Per-Thread Maps (Best Performance)**
```cpp
// No locks needed!
thread_local absl::flat_hash_map<AccountID, Position> local_positions;

// Update (no lock!)
local_positions[account_id].quantity += fill_qty;  // ~30ns

// Aggregate periodically (every 100ms)
void aggregate_positions() {
    for (auto& thread_map : all_thread_maps) {
        for (auto& [account, pos] : thread_map) {
            global_positions[account] += pos;
        }
    }
}
```

**Performance:**
- With lock: ~80ns per operation
- Per-thread: **~30ns per operation** â­
- **2.5x faster with per-thread approach!**

---

### Use Case 4: Reference Data

**Requirement:**
- 100,000 securities
- Read-only after initialization
- Multiple lookup keys (symbol, ISIN, SEDOL)
- Minimal memory

**Solution:**
```cpp
// Primary index (owns data)
folly::sorted_vector_map<std::string, SecurityData> by_symbol;

// Secondary indices (pointers)
folly::sorted_vector_map<std::string, SecurityData*> by_isin;
folly::sorted_vector_map<std::string, SecurityData*> by_sedol;

// Build once at startup
void initialize() {
    std::vector<std::pair<std::string, SecurityData>> data;
    // ... load from database ...
    
    by_symbol = folly::sorted_vector_map<...>(data.begin(), data.end());
    
    // Build secondary indices
    for (auto& [symbol, sec] : by_symbol) {
        by_isin[sec.isin] = &sec;
        by_sedol[sec.sedol] = &sec;
    }
}

// Ultra-fast lookups
auto it = by_symbol.find("AAPL");     // ~20ns â­
auto it2 = by_isin.find("US0378...");  // ~20ns â­
```

**Performance:**
- Lookup: 20-30ns (vs 80-100ns STL) = **70% faster** â­â­â­
- Memory: 40% of STL = **60% savings**

---

### Use Case 5: Time Series Data

**Requirement:**
- Store ticks in time order
- Range queries (time window)
- VWAP/TWAP calculations
- Append-only

**Solution:**
```cpp
// For append-only, use std::deque (best for this case)
std::deque<Tick> recent_ticks;

// Or for fixed window
template<typename T, size_t N>
class RingBuffer {
    std::array<T, N> buffer_;
    size_t head_ = 0;
    
public:
    void push(const T& item) {
        buffer_[head_++ % N] = item;
    }
    
    // Fast iteration for VWAP
    double calculate_vwap() const {
        double sum_pv = 0, sum_v = 0;
        for (const auto& tick : buffer_) {
            sum_pv += tick.price * tick.volume;
            sum_v += tick.volume;
        }
        return sum_pv / sum_v;
    }
};

RingBuffer<Tick, 1000> last_1000_ticks;
```

**Why std::deque for append-only:**
- O(1) push_back
- Cache-friendly iteration
- No reallocation
- **Better than hash maps for this use case**

---

## Installation Guide

### Installing Abseil (Recommended)

```bash
# Clone repository
git clone https://github.com/abseil/abseil-cpp.git
cd abseil-cpp

# Build
mkdir build && cd build
cmake .. -DCMAKE_CXX_STANDARD=17 -DCMAKE_BUILD_TYPE=Release
make -j$(nproc)
sudo make install

# Verify
ls /usr/local/include/absl/container/
# Should see: flat_hash_map.h, btree_map.h, etc.
```

**Compile with Abseil:**
```bash
g++ -std=c++20 -O3 -march=native -pthread program.cpp \
    -labsl_hash -labsl_raw_hash_set
```

---

### Installing Folly (Optional, for Best Performance)

```bash
# Install dependencies (Ubuntu/Debian)
sudo apt-get install -y \
    libgoogle-glog-dev \
    libgflags-dev \
    libevent-dev \
    libdouble-conversion-dev \
    libssl-dev \
    libboost-all-dev

# Clone and build
git clone https://github.com/facebook/folly.git
cd folly
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j$(nproc)
sudo make install
```

**Compile with Folly:**
```bash
g++ -std=c++20 -O3 -march=native -pthread program.cpp \
    -lfolly -lglog -lgflags -ldl
```

---

## Decision Matrix

### Hash Maps

| Requirement | Container | Why |
|-------------|-----------|-----|
| **General purpose** | `abseil::flat_hash_map` â­ | Best balance |
| **Best performance** | `folly::F14FastMap` â­â­â­ | Fastest |
| **Small values** | `folly::F14ValueMap` â­â­ | Inline storage |
| **Portability** | `std::unordered_map` | Standard |
| **Lock-free** | `folly::AtomicHashMap` | High contention |

### Ordered Maps

| Requirement | Container | Why |
|-------------|-----------|-----|
| **General purpose** | `abseil::btree_map` â­ | Fast + ordered |
| **Read-heavy** | `folly::sorted_vector_map` â­â­â­ | Fastest reads |
| **Order book** | `abseil::btree_map` â­ | Range queries |
| **Portability** | `std::map` | Standard |

### By Trading Use Case

| Use Case | Container | Latency | Reason |
|----------|-----------|---------|--------|
| Order tracking | `flat_hash_map` | 25-35ns | Fast lookups |
| Price levels | `btree_map` | 40-60ns | Ordered + ranges |
| Symbol cache | `flat_hash_map` | 25-35ns | Memory efficient |
| Positions | `flat_hash_map` | 25-35ns | Updates + reads |
| Reference data | `sorted_vector_map` | 20-30ns | Read-only |
| Time series | `std::deque` or ring buffer | 5-10ns | Sequential |

---

## Performance Summary

### Latency Comparison (nanoseconds)

```
Hash Map Lookup:
std::unordered_map:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 60ns
flat_hash_map:          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 30ns       â¬… 50% faster â­
F14FastMap:             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 25ns        â¬… 60% faster â­â­

Ordered Map Lookup:
std::map:               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100ns
btree_map:              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 50ns     â¬… 50% faster â­
sorted_vector_map:      â–ˆâ–ˆâ–ˆâ–ˆ 25ns         â¬… 75% faster â­â­â­
```

### Memory Comparison

```
Relative to std::unordered_map (100%):

flat_hash_map:          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 60%     â¬… 40% savings
F14FastMap:             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 50%        â¬… 50% savings
sorted_vector_map:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 30%             â¬… 70% savings â­
```

---

## Final Recommendations

### ğŸ¥‡ For 80% of Trading Use Cases

**Use Abseil:**
- `flat_hash_map` for unordered data
- `btree_map` for ordered data

**Why:**
- âœ“ 40-60% performance improvement
- âœ“ 30-50% memory savings
- âœ“ Easy integration (single dependency)
- âœ“ Proven in production (Google, Bloomberg)
- âœ“ Active maintenance

### ğŸ¥ˆ For Maximum Performance (Hot Paths)

**Use Folly:**
- `F14FastMap` / `F14ValueMap`
- `sorted_vector_map` for read-heavy

**Why:**
- âœ“ 60-80% performance improvement
- âœ“ 40-60% memory savings
- âœ“ Best-in-class performance
- âœ— Heavier dependencies

### ğŸ¥‰ Avoid in Hot Paths

**Don't use:**
- `std::unordered_map` â†’ 2x slower than alternatives
- `std::map` â†’ 2-3x slower than alternatives

**Use STL only for:**
- Prototyping
- Non-critical paths
- Maximum portability requirements

---

## Quick Start

### Minimal Example with Abseil

```cpp
#include "absl/container/flat_hash_map.h"
#include <iostream>

struct Order {
    uint64_t id;
    double price;
    int quantity;
};

int main() {
    // Create order tracking map
    absl::flat_hash_map<uint64_t, Order> orders;
    orders.reserve(10000);
    
    // Add order (fast: ~30ns)
    orders[12345] = {12345, 150.25, 100};
    
    // Lookup order (fast: ~25ns)
    auto it = orders.find(12345);
    if (it != orders.end()) {
        std::cout << "Order " << it->second.id 
                  << " @ " << it->second.price << "\n";
    }
    
    return 0;
}
```

**Compile:**
```bash
g++ -std=c++20 -O3 program.cpp -labsl_hash -labsl_raw_hash_set
```

---

## Benchmarking Your System

Run the included benchmark:

```bash
# Compile
g++ -std=c++20 -O3 -march=native -pthread \
    stl_abseil_folly_containers_comparison.cpp \
    -o benchmark

# Run
./benchmark
```

**Expected output:**
- Insert/lookup/erase timings
- Memory usage comparison
- Trading use case recommendations
- Decision matrix

---

## Conclusion

For ultra-low latency trading systems:

1. **Replace `std::unordered_map` with `abseil::flat_hash_map`** â†’ 50% faster â­
2. **Replace `std::map` with `abseil::btree_map`** â†’ 50% faster â­
3. **Use `folly::sorted_vector_map` for read-only data** â†’ 75% faster â­â­â­
4. **Consider `folly::F14FastMap` for critical hot paths** â†’ 60% faster â­â­

**Impact on Trading System:**
- Order book latency: 100ns â†’ 50ns
- Symbol lookup: 60ns â†’ 25ns
- Total tick-to-trade: **Reduce by 30-50%** ğŸš€

**Bottom line:** Modern containers are a **free 2x performance boost** with minimal code changes!

